{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EUvkZo1KxO9F",
        "9Iq1xLNTzEPo",
        "cVFMMLrxyFSw",
        "FAOe93FRMk3w",
        "j0DGH_4T0VYn",
        "unP3cnxo_N72",
        "QAwvlgSNoK3o"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvlrVi5YxEXf"
      },
      "source": [
        "# **PRÁCTICA 2: AUTOENCODERS - Parte 2: Convolucionales**\n",
        "### Universitat de València, Escola Tecnica Superior d'Enginyeria\n",
        "### Elena Marrero Castellano | 4ª curso del Grado Ciencia de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio Extra 1: Incluye regularización de actividad en el dominio interno y compara los resultados**\n",
        "---"
      ],
      "metadata": {
        "id": "WDDZG8jFyE5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder convolucional"
      ],
      "metadata": {
        "id": "JzSlgyaWxJi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Codificador automático convolucional**\n",
        "\n",
        "<p align=\"justify\">Dado que nuestras entradas son imágenes, tiene sentido utilizar redes neuronales convolucionales (convnets) como codificadores y decodificadores. En entornos prácticos, los codificadores automáticos aplicados a las imágenes son siempre codificadores automáticos convolucionales, simplemente funcionan mucho mejor.</p>\n",
        "\n",
        "<p align=\"justify\">Implementemos uno. El codificador consistirá en una pila de capas Conv2Dy MaxPooling2D(la agrupación máxima se utiliza para el muestreo descendente espacial), mientras que el decodificador consistirá en una pila de capas Conv2Dy .UpSampling2D.</p>\n",
        "\n",
        "<p align=\"justify\">Es decir, comenzaremos de manera simple, con una sola capa neuronal completamente conectada como codificador y decodificador:</p>"
      ],
      "metadata": {
        "id": "gR-BIipdzWci"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPYuKtjYTSD_"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSq5lDFkWAh_"
      },
      "source": [
        "# MODELO\n",
        "\n",
        "# ENCODER activity_regularizer (parámentro de las Dense); activity_regularizer = regularizers.l1(0.01)\n",
        "input_img = Input(shape=(28, 28, 1))  \n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# DECODER\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnGJRQIJje5k"
      },
      "source": [
        "opt = Adam(learning_rate=0.0001)\n",
        "autoencoder0 = Model(input_img, decoded)\n",
        "autoencoder0.compile(optimizer=opt, loss='mse')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder0.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-iLOVYOHp3B",
        "outputId": "0e061fdb-9604-4a9a-ccf1-c6e7cbd52acc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 8)         1160      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 8)           584       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 8, 8, 8)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 16, 16, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 16)        1168      \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 28, 28, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 1)         145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,385\n",
            "Trainable params: 4,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">Para entrenarlo, usaremos los dígitos MNIST originales:</p>"
      ],
      "metadata": {
        "id": "lUnTiqpvzjiE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrlLun-TFA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4141c9-c5bd-4dc3-a4d9-75b4ea8e96c7"
      },
      "source": [
        "# DATOS\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) \n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">Entrenemos este modelo durante 100 épocas.</p>"
      ],
      "metadata": {
        "id": "H4dOnJskzvgh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3defT4BpTG5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1febf75-fa9f-4760-c05c-f50d3f5e5457"
      },
      "source": [
        "# ENTRENAMIENTO\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder0.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 15s 7ms/step - loss: 0.1194 - val_loss: 0.0606\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0508 - val_loss: 0.0449\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0426 - val_loss: 0.0400\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0383 - val_loss: 0.0360\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0345 - val_loss: 0.0326\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0315 - val_loss: 0.0299\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0291 - val_loss: 0.0279\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0274 - val_loss: 0.0263\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - val_loss: 0.0251\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0249 - val_loss: 0.0241\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0239 - val_loss: 0.0232\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0230 - val_loss: 0.0224\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0223 - val_loss: 0.0216\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0216 - val_loss: 0.0211\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0210 - val_loss: 0.0205\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0205 - val_loss: 0.0200\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0201 - val_loss: 0.0196\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0196 - val_loss: 0.0192\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0192 - val_loss: 0.0188\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0188 - val_loss: 0.0185\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0185 - val_loss: 0.0181\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0182 - val_loss: 0.0178\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0179 - val_loss: 0.0175\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0176 - val_loss: 0.0172\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0173 - val_loss: 0.0170\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0171 - val_loss: 0.0167\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0169 - val_loss: 0.0165\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0167 - val_loss: 0.0164\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0165 - val_loss: 0.0162\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0163 - val_loss: 0.0160\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0161 - val_loss: 0.0158\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - val_loss: 0.0157\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0158 - val_loss: 0.0155\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0157 - val_loss: 0.0154\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0155 - val_loss: 0.0153\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0154 - val_loss: 0.0152\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0153 - val_loss: 0.0151\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0152 - val_loss: 0.0149\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0151 - val_loss: 0.0148\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0150 - val_loss: 0.0147\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0149 - val_loss: 0.0146\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0148 - val_loss: 0.0145\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0147 - val_loss: 0.0144\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0146 - val_loss: 0.0143\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0145 - val_loss: 0.0143\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0144 - val_loss: 0.0142\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - val_loss: 0.0141\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - val_loss: 0.0140\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0142 - val_loss: 0.0140\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0141 - val_loss: 0.0139\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0140 - val_loss: 0.0138\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0140 - val_loss: 0.0138\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0139 - val_loss: 0.0137\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0138 - val_loss: 0.0136\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0138 - val_loss: 0.0136\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0137 - val_loss: 0.0135\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0136 - val_loss: 0.0133\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0135 - val_loss: 0.0132\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0132\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0134 - val_loss: 0.0131\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0133 - val_loss: 0.0131\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0133 - val_loss: 0.0131\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0130\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0132 - val_loss: 0.0130\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0131 - val_loss: 0.0129\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0131 - val_loss: 0.0129\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0131 - val_loss: 0.0128\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0129 - val_loss: 0.0127\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0129 - val_loss: 0.0127\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0129 - val_loss: 0.0126\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - val_loss: 0.0126\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - val_loss: 0.0126\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - val_loss: 0.0125\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - val_loss: 0.0125\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0127 - val_loss: 0.0125\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0126 - val_loss: 0.0123\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - val_loss: 0.0123\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - val_loss: 0.0123\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - val_loss: 0.0122\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0124 - val_loss: 0.0122\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0124 - val_loss: 0.0122\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0124 - val_loss: 0.0122\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0123 - val_loss: 0.0121\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0123 - val_loss: 0.0121\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0123 - val_loss: 0.0120\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - val_loss: 0.0120\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - val_loss: 0.0120\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - val_loss: 0.0120\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0122 - val_loss: 0.0119\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0121 - val_loss: 0.0119\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0121 - val_loss: 0.0119\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0121 - val_loss: 0.0119\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0120 - val_loss: 0.0118\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0120 - val_loss: 0.0118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98c4081c90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">Después de 100 épocas, el codificador automático parece alcanzar un valor de pérdida de validación/entrenamiento estable de aproximadamente 0.0122. Podemos intentar visualizar las entradas reconstruidas y las representaciones codificadas. Usaremos Matplotlib en el siguiente apartado.</p>"
      ],
      "metadata": {
        "id": "_J7go_kY-Xt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder convolucional con regularizador "
      ],
      "metadata": {
        "id": "LUtnkvNADGqC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghCWWvKaqd8S"
      },
      "source": [
        "# MODELO\n",
        "\n",
        "# ENCODER \n",
        "input_img = Input(shape=(28, 28, 1))  \n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same',activity_regularizer = regularizers.l1(0.01))(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# DECODER\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrZrxMZoqd8S"
      },
      "source": [
        "opt = Adam(learning_rate=0.0001)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer=opt, loss='mse')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73743bbf-4790-404c-b252-231283a3a0d0",
        "id": "u8AcBMe2qd8S"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 14, 14, 8)         1160      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 8)           584       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 4, 4, 8)           584       \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSampling  (None, 8, 8, 8)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 8)           584       \n",
            "                                                                 \n",
            " up_sampling2d_4 (UpSampling  (None, 16, 16, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 16)        1168      \n",
            "                                                                 \n",
            " up_sampling2d_5 (UpSampling  (None, 28, 28, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 28, 28, 1)         145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,385\n",
            "Trainable params: 4,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d82875-d52d-4a1c-cc81-edf1481adbf3",
        "id": "zuV0_8gfqd8T"
      },
      "source": [
        "# ENTRENAMIENTO\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 1.7228 - val_loss: 0.6034\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3073 - val_loss: 0.1618\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1222 - val_loss: 0.0960\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0847 - val_loss: 0.0762\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0717 - val_loss: 0.0685\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0665 - val_loss: 0.0650\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0638 - val_loss: 0.0628\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0618 - val_loss: 0.0609\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0598 - val_loss: 0.0588\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0577 - val_loss: 0.0567\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0558 - val_loss: 0.0549\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0541 - val_loss: 0.0533\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0525 - val_loss: 0.0517\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0510 - val_loss: 0.0502\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0496 - val_loss: 0.0489\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0483 - val_loss: 0.0476\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0467 - val_loss: 0.0458\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0453 - val_loss: 0.0447\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0442 - val_loss: 0.0436\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0432 - val_loss: 0.0426\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0423 - val_loss: 0.0419\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0415 - val_loss: 0.0410\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0408 - val_loss: 0.0403\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0401 - val_loss: 0.0396\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0393 - val_loss: 0.0383\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0379 - val_loss: 0.0371\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0364 - val_loss: 0.0354\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0353 - val_loss: 0.0345\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0345 - val_loss: 0.0337\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0338 - val_loss: 0.0332\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0333 - val_loss: 0.0327\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0328 - val_loss: 0.0322\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0324 - val_loss: 0.0319\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0321 - val_loss: 0.0315\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0317 - val_loss: 0.0312\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0314 - val_loss: 0.0308\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0311 - val_loss: 0.0307\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0309 - val_loss: 0.0307\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0306 - val_loss: 0.0301\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0304 - val_loss: 0.0299\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0301 - val_loss: 0.0297\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0299 - val_loss: 0.0294\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0297 - val_loss: 0.0292\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0295 - val_loss: 0.0290\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0293 - val_loss: 0.0289\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0291 - val_loss: 0.0285\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0289 - val_loss: 0.0283\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0287 - val_loss: 0.0281\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0285 - val_loss: 0.0280\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0283 - val_loss: 0.0278\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0281 - val_loss: 0.0277\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0279 - val_loss: 0.0275\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0277 - val_loss: 0.0275\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0275 - val_loss: 0.0270\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0274 - val_loss: 0.0269\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0272 - val_loss: 0.0266\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0270 - val_loss: 0.0264\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0267 - val_loss: 0.0263\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0265 - val_loss: 0.0261\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0263 - val_loss: 0.0257\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - val_loss: 0.0255\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0257 - val_loss: 0.0252\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0255 - val_loss: 0.0249\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0252 - val_loss: 0.0247\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0249 - val_loss: 0.0245\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0248 - val_loss: 0.0243\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0245 - val_loss: 0.0240\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0244 - val_loss: 0.0238\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0242 - val_loss: 0.0237\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0240 - val_loss: 0.0236\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0239 - val_loss: 0.0235\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0237 - val_loss: 0.0236\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0236 - val_loss: 0.0231\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0234 - val_loss: 0.0231\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0233 - val_loss: 0.0235\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0232 - val_loss: 0.0232\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0230 - val_loss: 0.0229\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0230 - val_loss: 0.0225\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0228 - val_loss: 0.0224\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0227 - val_loss: 0.0225\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0227 - val_loss: 0.0222\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0226 - val_loss: 0.0221\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0225 - val_loss: 0.0220\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0224 - val_loss: 0.0221\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0223 - val_loss: 0.0218\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0222 - val_loss: 0.0219\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0221 - val_loss: 0.0218\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0221 - val_loss: 0.0215\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0220 - val_loss: 0.0216\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0219 - val_loss: 0.0216\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0219 - val_loss: 0.0218\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0218 - val_loss: 0.0215\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0218 - val_loss: 0.0216\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0217 - val_loss: 0.0213\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0216 - val_loss: 0.0213\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0216 - val_loss: 0.0210\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0215 - val_loss: 0.0210\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0214 - val_loss: 0.0220\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0214 - val_loss: 0.0208\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0213 - val_loss: 0.0210\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98ac7150d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparamos"
      ],
      "metadata": {
        "id": "Vz5hlDxRDZSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convolucional\n",
        "decoded_imgs0 = autoencoder0.predict(x_test)"
      ],
      "metadata": {
        "id": "nSuIt0AoS6ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09151ff-1c83-4ecf-be16-ae465fdd081f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convolucional + regularizador\n",
        "decoded_imgs1 = autoencoder.predict(x_test)"
      ],
      "metadata": {
        "id": "LCWKLE-TSn-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8881eda-aed5-47f4-edb3-be0a98b5a52d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Imágenes originales\")\n",
        "for i in range(1, n + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Reconstrucción (convolucional):\")\n",
        "for i in range(1, n + 1):\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs0[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Reconstrucción (convolucional + regularizador):\")\n",
        "for i in range(1, n + 1):\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs1[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "77f17c27-fd81-4833-a6a2-4c34c3532161",
        "id": "gRoyTBfjqd8U"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes originales\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstrucción (convolucional):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstrucción (convolucional + regularizador):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">Las estrategias de regularización incorporan penalizaciones en el ajuste por mínimos cuadrados ordinarios (OLS) con el objetivo de evitar overfitting, reducir varianza, atenuar el efecto de la correlación entre predictores y minimizar la influencia en el modelo de los predictores menos relevantes. Por lo general, aplicando regularización se consigue modelos con mayor poder predictivo (generalización).</p>\n",
        "\n",
        "\n",
        "<p align=\"justify\">Los regularizadores le permiten aplicar penalizaciones en los parámetros de la capa o la actividad de la capa durante la optimización. Estas penalizaciones se suman a la función de pérdida que optimiza la red. En este caso se ha añadido un regularizador de actividad, este aplica una penalización en la salida de la capa.</p>\n",
        "\n",
        "<p align=\"justify\">Por lo tanto, podemos decir que como regularizador de actividad lo que hace es penalizar la actividad de la capa, consiguiendo así que generalice mejor y que no entremos en sobre ajuste, por lo tanto, puede pasar que la recontrucción nos salga peor. Este no es el caso, la visualización de los dígitos es bastant4e parecida.</p>"
      ],
      "metadata": {
        "id": "VPoKOxns3l_-"
      }
    }
  ]
}